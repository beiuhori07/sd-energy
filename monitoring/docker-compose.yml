version: "3.6"

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.0
    container_name: zookeeper-energy
    restart: on-failure
#    volumes:
#      - zookeeperdata:/var/lib/zookeeper/data
#      - zookeeperlog:/var/lib/zookeeper/log
#      - zookeeper:/var/log/zookeeper
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_SERVERS: zookeeper:2888:3888
    network_mode: "host"
  kafka:
      image: confluentinc/cp-kafka:7.0.0
      container_name: kafka-energy
      restart: on-failure
#      volumes:
#        - kafkadata:/var/lib/kafka/data
#        - kafka:/var/log/kafka
      depends_on:
        - zookeeper
      environment:
        KAFKA_BROKER_ID: 1
        KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
        KAFKA_ZOOKEEPER_CONNECT: localhost:2181
        KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
        KAFKA_LISTENERS: INSIDE://:9092,OUTSIDE_LOCAL_HOST://:9093
        KAFKA_ADVERTISED_LISTENERS: INSIDE://localhost:9092,OUTSIDE_LOCAL_HOST://localhost:9093
        KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE_LOCAL_HOST:PLAINTEXT
        KAFKA_DELETE_TOPIC_ENABLE: "true"
        KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
        KAFKA_REPLICA_FETCH_MAX_BYTES: 30000000
        KAFKA_PRODUCER_MAX_REQUEST_SIZE: 30000000
        KAFKA_CONSUMER_MAX_PARTITION_FETCH_BYTES: 30000000
        KAFKA_MESSAGE_MAX_BYTES: 30000000
        KAFKA_LOG_RETENTION_MS: 3600000
        KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 60000
      network_mode: "host"
  init-kafka:
      image: confluentinc/cp-kafka:7.0.0
      container_name: init-kafka-energy
      depends_on:
        - kafka
      command: [ "/bin/sh", "/create-topics.sh" ]
      volumes:
        - type: bind
          source: ./create-topics.sh
          target: /create-topics.sh
      network_mode: "host"
